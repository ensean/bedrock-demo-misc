#!/usr/bin/env python3
"""
ä½¿ç”¨ Strands Agent SDK åˆ†æ EC2 æ€§èƒ½æ•°æ®
æ¼”ç¤ºï¼šå¤§æ¨¡å‹ç”Ÿæˆä»£ç  -> python_repl è¿è¡Œ -> å¤§æ¨¡å‹åˆ†æç»“æœ
"""

import os
import json
from strands import Agent
from strands_tools import calculator, file_read, shell, python_repl
from strands.models import BedrockModel

os.environ["BYPASS_TOOL_CONSENT"] = "true"

bedrock_model = BedrockModel(
    model_id="global.anthropic.claude-sonnet-4-5-20250929-v1:0",
    temperature=0.3)

system_prompt = """ä½œä¸ºç›‘æ§ç³»ç»Ÿä¸“å®¶ï¼Œåˆ†æç›‘æ§æŒ‡æ ‡å¹¶ç»™å‡ºå»ºè®®ï¼Œè¾“å‡ºä¿æŒç®€æ´"""


def get_token_stats_from_trace(trace):
    """Extract token usage statistics from trace result."""
    stats = {
        "input_tokens": 0,
        "output_tokens": 0,
        "cache_creation_tokens": 0,
        "cache_read_tokens": 0,
        "total_tokens": 0
    }
    
    # Get metrics from trace
    if hasattr(trace, 'metrics'):
        metrics_summary = trace.metrics.get_summary()
        accumulated_usage = metrics_summary.get("accumulated_usage", {})
        
        stats["input_tokens"] = accumulated_usage.get("inputTokens", 0)
        stats["output_tokens"] = accumulated_usage.get("outputTokens", 0)
        stats["total_tokens"] = accumulated_usage.get("totalTokens", 0)
        
        # Check for cache tokens in the usage details
        if "cacheCreationInputTokens" in accumulated_usage:
            stats["cache_creation_tokens"] = accumulated_usage.get("cacheCreationInputTokens", 0)
        if "cacheReadInputTokens" in accumulated_usage:
            stats["cache_read_tokens"] = accumulated_usage.get("cacheReadInputTokens", 0)
    
    return stats


def analyze_ec2_metrics_file():
    """ä½¿ç”¨ Strands Agent åˆ†æ EC2 æ€§èƒ½æ•°æ®"""
    
    print("=" * 70)
    print("Strands Agent File content æ¼”ç¤º")
    print("åˆ†æ EC2 æœåŠ¡å™¨æ€§èƒ½æ•°æ®")
    print("=" * 70)
    print()

    # åˆ›å»º Strands Agentï¼ˆè‡ªåŠ¨åŒ…å« python_repl toolï¼‰
    agent = Agent(
        model=bedrock_model,
        system_prompt=system_prompt,
        tools=[file_read, calculator]
    )

    # æ„å»ºåˆ†æè¯·æ±‚
    csv_file_name = 'data/ec2_metrics.csv'

    with open(csv_file_name, "rb") as fp:
        csv_bytes = fp.read()

    user_prompt = f"""
æˆ‘æœ‰ä¸€ä»½ EC2 æœåŠ¡å™¨çš„æ€§èƒ½ç›‘æ§æ•°æ®ï¼ˆCSV æ ¼å¼ï¼‰ï¼Œå­˜å‚¨åœ¨ csv ä¸­ï¼š
è¯·æ‰§è¡Œä»¥ä¸‹åŠ¨ä½œï¼š
1. è¯†åˆ«å­˜åœ¨æ€§èƒ½é£é™©çš„å®ä¾‹ï¼ˆå¹³å‡ä½¿ç”¨ç‡ CPU > 90% æˆ– å†…å­˜ > 85%ï¼‰
2. ç»™å‡ºå»ºè®®
"""
    analysis_request = [
        {"text": user_prompt},
        {
            "document": {
                "format": "csv",
                "name": "ec2_metrics",
                "source": {
                    "bytes": csv_bytes
                }
            }
        }
    ]
    print("ğŸ‘¤ ç”¨æˆ·è¯·æ±‚:")
    print("-" * 70)
    print("åˆ†æ EC2 æœåŠ¡å™¨æ€§èƒ½æ•°æ®...")
    print()
    
    print("ğŸ¤– Strands Agent å¼€å§‹å·¥ä½œ...\n")
    
    # è¿è¡Œ Agentï¼ˆè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯ï¼‰
    trace = agent(analysis_request)
    
    stats = get_token_stats_from_trace(trace)
    print("------------------\n ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡:" + json.dumps(stats, indent=4))



def analyze_ec2_metrics_repl():
    """ä½¿ç”¨ Strands Agent åˆ†æ EC2 æ€§èƒ½æ•°æ®"""
    
    print("=" * 70)
    print("Strands Agent Python REPL æ¼”ç¤º")
    print("åˆ†æ EC2 æœåŠ¡å™¨æ€§èƒ½æ•°æ®")
    print("=" * 70)
    print()

    # åˆ›å»º Strands Agentï¼ˆè‡ªåŠ¨åŒ…å« python_repl toolï¼‰
    agent = Agent(
        model=bedrock_model,
        system_prompt=system_prompt,
        tools=[python_repl, file_read, shell, calculator]
    )

    # æ„å»ºåˆ†æè¯·æ±‚
    csv_file_name = 'data/ec2_metrics.csv'
    analysis_request = f"""
æˆ‘æœ‰ä¸€ä»½ EC2 æœåŠ¡å™¨çš„æ€§èƒ½ç›‘æ§æ•°æ®ï¼ˆCSV æ ¼å¼ï¼‰ï¼Œå­˜å‚¨åœ¨{csv_file_name}ï¼š
è¯·æ‰§è¡Œä»¥ä¸‹åŠ¨ä½œï¼š
1. è¯†åˆ«å­˜åœ¨æ€§èƒ½é£é™©çš„å®ä¾‹ï¼ˆå¹³å‡ä½¿ç”¨ç‡ CPU > 90% æˆ– å†…å­˜ > 85%ï¼‰
2. ç»™å‡ºå»ºè®®
"""
    print("ğŸ‘¤ ç”¨æˆ·è¯·æ±‚:")
    print("-" * 70)
    print("åˆ†æ EC2 æœåŠ¡å™¨æ€§èƒ½æ•°æ®...")
    print()
    
    print("ğŸ¤– Strands Agent å¼€å§‹å·¥ä½œ...\n")
    
    # è¿è¡Œ Agentï¼ˆè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯ï¼‰
    trace = agent(analysis_request)
    
    stats = get_token_stats_from_trace(trace)
    print("\n------------------\n ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡:" + json.dumps(stats, indent=4))

if __name__ == "__main__":
    try:
        analyze_ec2_metrics_file()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("\nè¯·ç¡®ä¿ï¼š")
        print("1. å·²å®‰è£… Strands Agent SDK: pip install anthropic-strands")
        import traceback
        traceback.print_exc()
