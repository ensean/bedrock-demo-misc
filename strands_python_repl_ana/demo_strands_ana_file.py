#!/usr/bin/env python3
"""
ä½¿ç”¨ Strands Agent SDK åˆ†æ EC2 æ€§èƒ½æ•°æ®
æ¼”ç¤ºï¼šå¤§æ¨¡å‹ç”Ÿæˆä»£ç  -> python_repl è¿è¡Œ -> å¤§æ¨¡å‹åˆ†æç»“æœ
"""

import os
import json
from strands import Agent
from strands_tools import calculator, file_read, shell, python_repl
from strands.models import BedrockModel

from strands.agent.conversation_manager import (
    NullConversationManager,
    SlidingWindowConversationManager,
    SummarizingConversationManager
)

sum_manager = SummarizingConversationManager(
    summary_ratio=0.3,
    preserve_recent_messages=2
)

slide_manager = SlidingWindowConversationManager(
    window_size=2
)

def event_loop_tracker(**kwargs):
    # Track event loop lifecycle
    complete = kwargs.get("complete", False)


    if "current_tool_use" in kwargs and kwargs["current_tool_use"].get("name"):
        print(f"\nUSING TOOL: {kwargs['current_tool_use']['name']}")
        print("type: ", kwargs.get("type"))
        print("request_state: ", kwargs.get("request_state"))
        


os.environ["BYPASS_TOOL_CONSENT"] = "true"

bedrock_model = BedrockModel(
    model_id="global.anthropic.claude-sonnet-4-5-20250929-v1:0",
    temperature=0.3)

system_prompt = """ä½œä¸ºç›‘æ§ç³»ç»Ÿä¸“å®¶ï¼Œä»”ç»†åˆ†æç›‘æ§æŒ‡æ ‡"""


def get_token_stats_from_trace(trace):
    """Extract token usage statistics from trace result."""
    stats = {
        "input_tokens": 0,
        "output_tokens": 0,
        "cache_creation_tokens": 0,
        "cache_read_tokens": 0,
        "total_tokens": 0
    }
    
    # Get metrics from trace
    if hasattr(trace, 'metrics'):
        metrics_summary = trace.metrics.get_summary()
        accumulated_usage = metrics_summary.get("accumulated_usage", {})
        
        stats["input_tokens"] = accumulated_usage.get("inputTokens", 0)
        stats["output_tokens"] = accumulated_usage.get("outputTokens", 0)
        stats["total_tokens"] = accumulated_usage.get("totalTokens", 0)
        
        # Check for cache tokens in the usage details
        if "cacheCreationInputTokens" in accumulated_usage:
            stats["cache_creation_tokens"] = accumulated_usage.get("cacheCreationInputTokens", 0)
        if "cacheReadInputTokens" in accumulated_usage:
            stats["cache_read_tokens"] = accumulated_usage.get("cacheReadInputTokens", 0)
    
    return stats


def analyze_ec2_metrics_file():
    """ä½¿ç”¨ Strands Agent åˆ†æ EC2 æ€§èƒ½æ•°æ®"""
    
    print("=" * 70)
    print("Strands Agent File content æ¼”ç¤º")
    print("åˆ†æ EC2 æœåŠ¡å™¨æ€§èƒ½æ•°æ®")
    print("=" * 70)
    print()

    # åˆ›å»º Strands Agentï¼ˆè‡ªåŠ¨åŒ…å« python_repl toolï¼‰
    agent = Agent(
        model=bedrock_model,
        system_prompt=system_prompt,
        tools=[file_read, calculator],
        callback_handler=None
    )

    # æ„å»ºåˆ†æè¯·æ±‚
    csv_file_name = 'data/ec2_metrics.csv'

    with open(csv_file_name, "rb") as fp:
        csv_bytes = fp.read()

    user_prompt = f"""
æˆ‘æœ‰ä¸€ä»½ EC2 æœåŠ¡å™¨çš„æ€§èƒ½ç›‘æ§æ•°æ®ï¼ˆCSV æ ¼å¼ï¼‰ï¼Œè¯·æ‰¾å‡ºå¹³å‡ CPU ä½¿ç”¨ç‡å¤§äº 75% çš„æœºå™¨
"""
    analysis_request = [
        {"text": user_prompt},
        {
            "document": {
                "format": "csv",
                "name": "ec2_metrics",
                "source": {
                    "bytes": csv_bytes
                }
            }
        }
    ]
    print("ğŸ‘¤ ç”¨æˆ·è¯·æ±‚:")
    print("-" * 70)
    print("åˆ†æ EC2 æœåŠ¡å™¨æ€§èƒ½æ•°æ®...")
    print()
    
    print("ğŸ¤– Strands Agent å¼€å§‹å·¥ä½œ...\n")
    
    # è¿è¡Œ Agentï¼ˆè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯ï¼‰
    trace = agent(analysis_request)
    print("\n------------------\nğŸ¤– Strands Agent ç»“æœ:")
    print(trace)
    stats = get_token_stats_from_trace(trace)
    print("------------------\n ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡:" + json.dumps(stats, indent=4))



def analyze_ec2_metrics_repl():
    """ä½¿ç”¨ Strands Agent åˆ†æ EC2 æ€§èƒ½æ•°æ®"""
    
    print("=" * 70)
    print("Strands Agent Python REPL æ¼”ç¤º")
    print("åˆ†æ EC2 æœåŠ¡å™¨æ€§èƒ½æ•°æ®")
    print("=" * 70)
    print()

    # åˆ›å»º Strands Agentï¼ˆè‡ªåŠ¨åŒ…å« python_repl toolï¼‰
    agent = Agent(
        model=bedrock_model,
        system_prompt=system_prompt,
        tools=[python_repl, file_read, shell, calculator],
        callback_handler=None
    )

    # æ„å»ºåˆ†æè¯·æ±‚
    csv_file_name = 'data/ec2_metrics.csv'
    analysis_request = f"""
æˆ‘æœ‰ä¸€ä»½ EC2 æœåŠ¡å™¨çš„æ€§èƒ½ç›‘æ§æ•°æ®ï¼ˆCSV æ ¼å¼ï¼‰ï¼Œå­˜å‚¨åœ¨{csv_file_name}ï¼Œè¯·æ‰¾å‡ºå¹³å‡ CPU ä½¿ç”¨ç‡å¤§äº 75% çš„æœºå™¨
"""
    print("ğŸ‘¤ ç”¨æˆ·è¯·æ±‚:")
    print("-" * 70)
    print("åˆ†æ EC2 æœåŠ¡å™¨æ€§èƒ½æ•°æ®...")
    print()
    
    print("ğŸ¤– Strands Agent å¼€å§‹å·¥ä½œ...\n")
    
    # è¿è¡Œ Agentï¼ˆè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯ï¼‰
    trace = agent(analysis_request)
    

    print("\n------------------\nğŸ¤– Strands Agent ç»“æœ:")
    print(trace)

    stats = get_token_stats_from_trace(trace)
    print("\n------------------\nğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡:" + json.dumps(stats, indent=2))


if __name__ == "__main__":
    try:
        # analyze_ec2_metrics_repl()
        analyze_ec2_metrics_file()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("\nè¯·ç¡®ä¿ï¼š")
        print("1. å·²å®‰è£… Strands Agent SDK: pip install anthropic-strands")
        import traceback
        traceback.print_exc()
